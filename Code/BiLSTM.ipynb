{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNTTDhWbzUMm9IChmjvGzR+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayushverma41/Mental-State-Prediction-using-NLP/blob/main/Code/BiLSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "61CRMhDPssSX"
      },
      "outputs": [],
      "source": [
        "# ==========================================================\n",
        "# STEP 1: Import Dependencies\n",
        "# ==========================================================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import f1_score, confusion_matrix, accuracy_score, precision_score, recall_score\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from tqdm.auto import tqdm\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from transformers import BertTokenizer\n",
        "import joblib\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(\"Using device:\", device)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "5ihuGMFktR2G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_path = \"/content/drive/MyDrive/Mental State model/Data/Train_Data.csv\"\n",
        "# Add on_bad_lines='skip'\n",
        "df = pd.read_csv(train_data_path, on_bad_lines='skip')\n",
        "\n",
        "# The rest of your code\n",
        "assert \"statement\" in df.columns and \"status\" in df.columns, \"Dataset must have 'statement' and 'status' columns\"\n",
        "\n",
        "le = LabelEncoder()\n",
        "df['label'] = le.fit_transform(df['status'])\n",
        "num_classes = len(le.classes_)\n",
        "print(\"Classes:\", le.classes_)\n",
        "\n",
        "train_texts, val_texts, train_labels, val_labels = train_test_split(\n",
        "    df['statement'].values, df['label'].values, test_size=0.2, random_state=42\n",
        ")\n",
        "\n",
        "print(\"Data loaded and split successfully!\")\n"
      ],
      "metadata": {
        "id": "77UJfi46tVLF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "MAX_LEN = 64\n",
        "\n",
        "def encode_sentences(texts):\n",
        "    return [tokenizer.encode(text, add_special_tokens=True, truncation=True, max_length=MAX_LEN)\n",
        "            for text in texts]\n",
        "\n",
        "train_encodings = encode_sentences(train_texts)\n",
        "val_encodings = encode_sentences(val_texts)\n",
        "\n",
        "class MentalHealthDataset(Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        return torch.tensor(self.encodings[idx]), torch.tensor(self.labels[idx])\n",
        "\n",
        "def collate_fn(batch):\n",
        "    sentences, labels = zip(*batch)\n",
        "    sentences_padded = pad_sequence(sentences, batch_first=True, padding_value=0)\n",
        "    labels = torch.tensor(labels)\n",
        "    return sentences_padded, labels\n",
        "\n",
        "train_dataset = MentalHealthDataset(train_encodings, train_labels)\n",
        "val_dataset = MentalHealthDataset(val_encodings, val_labels)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True, collate_fn=collate_fn)\n",
        "val_loader = DataLoader(val_dataset, batch_size=32, collate_fn=collate_fn)\n"
      ],
      "metadata": {
        "id": "_-2n_ErttX4A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BiLSTMClassifier(nn.Module):\n",
        "    def __init__(self, vocab_size, embed_dim, hidden_dim, num_classes):\n",
        "        super(BiLSTMClassifier, self).__init__()\n",
        "        self.embedding = nn.Embedding(vocab_size, embed_dim, padding_idx=0)\n",
        "        self.lstm = nn.LSTM(embed_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "        self.fc = nn.Linear(hidden_dim * 2, num_classes)\n",
        "        self.batch_norm = nn.BatchNorm1d(num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        embeds = self.embedding(x)\n",
        "        lstm_out, _ = self.lstm(embeds)\n",
        "        avg_pool = torch.mean(lstm_out, dim=1)\n",
        "        out = self.dropout(avg_pool)\n",
        "        out = self.fc(out)\n",
        "        out = self.batch_norm(out)\n",
        "        return out\n",
        "\n",
        "vocab_size = tokenizer.vocab_size\n",
        "model = BiLSTMClassifier(vocab_size, 128, 128, num_classes).to(device)\n"
      ],
      "metadata": {
        "id": "KX4-f5e_tarG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=2e-4, weight_decay=1e-5)\n",
        "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', factor=0.5, patience=2)\n",
        "\n",
        "EPOCHS = 5\n",
        "patience = 3\n",
        "best_val_loss = float('inf')\n",
        "epochs_no_improve = 0\n",
        "\n",
        "train_losses, val_losses, val_f1_scores = [], [], []\n",
        "save_path = \"/content/drive/MyDrive/Mental State model/Model/BiLSTM/bilstm_model.pth\"\n"
      ],
      "metadata": {
        "id": "feT1K-mQtdJV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS):\n",
        "    model.train()\n",
        "    total_train_loss = 0\n",
        "    loop = tqdm(train_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False)\n",
        "\n",
        "    for inputs, labels in loop:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "\n",
        "        nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "        optimizer.step()\n",
        "        total_train_loss += loss.item()\n",
        "        loop.set_postfix(loss=loss.item())\n",
        "\n",
        "    avg_train_loss = total_train_loss / len(train_loader)\n",
        "    train_losses.append(avg_train_loss)\n",
        "\n",
        "    # Validation\n",
        "    model.eval()\n",
        "    val_loss, all_preds, all_labels = 0, [], []\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in val_loader:\n",
        "            inputs, labels = inputs.to(device), labels.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, labels)\n",
        "            val_loss += loss.item()\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "            all_preds.extend(preds.cpu().numpy())\n",
        "            all_labels.extend(labels.cpu().numpy())\n",
        "\n",
        "    avg_val_loss = val_loss / len(val_loader)\n",
        "    f1 = f1_score(all_labels, all_preds, average=\"weighted\")\n",
        "    val_losses.append(avg_val_loss)\n",
        "    val_f1_scores.append(f1)\n",
        "\n",
        "    scheduler.step(avg_val_loss)\n",
        "\n",
        "    print(f\"Epoch [{epoch+1}/{EPOCHS}] | Train Loss: {avg_train_loss:.4f} | Val Loss: {avg_val_loss:.4f} | F1: {f1:.4f}\")\n",
        "\n",
        "    # Early stopping\n",
        "    if avg_val_loss < best_val_loss:\n",
        "        best_val_loss = avg_val_loss\n",
        "        torch.save(model.state_dict(), save_path)\n",
        "        epochs_no_improve = 0\n",
        "        print(\"‚úÖ Model improved ‚Äî saved!\")\n",
        "    else:\n",
        "        epochs_no_improve += 1\n",
        "        if epochs_no_improve >= patience:\n",
        "            print(\"‚èπÔ∏è Early stopping triggered.\")\n",
        "            break\n"
      ],
      "metadata": {
        "id": "ZKQzkHVftgxe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# STEP X: Centralized Save Directory for All Images\n",
        "# ==========================================================\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# Create the save directory if it doesn‚Äôt exist\n",
        "save_dir = \"/content/drive/MyDrive/Mental State model/Images/BiLSTM/\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "print(f\"üìÅ All plots will be saved to: {save_dir}\")"
      ],
      "metadata": {
        "id": "y3T_DFAStn5h"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# STEP 7 (UPDATED): Training Visualization\n",
        "# ==========================================================\n",
        "plt.figure(figsize=(12,5))\n",
        "\n",
        "# Loss Plot\n",
        "plt.subplot(1,2,1)\n",
        "plt.plot(train_losses, label='Train Loss')\n",
        "plt.plot(val_losses, label='Validation Loss')\n",
        "plt.title('Loss over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "# F1 Score Plot\n",
        "plt.subplot(1,2,2)\n",
        "plt.plot(val_f1_scores, label='Validation F1 Score', color='orange')\n",
        "plt.title('F1 Score over Epochs')\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "loss_f1_plot_path = os.path.join(save_dir, \"Training_Loss_F1.png\")\n",
        "plt.savefig(loss_f1_plot_path, bbox_inches='tight', dpi=300)\n",
        "plt.close()\n",
        "\n",
        "print(f\"‚úÖ Saved: {loss_f1_plot_path}\")\n"
      ],
      "metadata": {
        "id": "9OSZXVIYtqrd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load best model\n",
        "model.load_state_dict(torch.load(save_path))\n",
        "model.eval()\n",
        "\n",
        "# Load test data\n",
        "test_data_path = \"/content/drive/MyDrive/Mental State model/Data/Test_Data.csv\"\n",
        "output_path = \"/content/drive/MyDrive/Mental State model/Data/MentalHealth_BiLSTM_Predictions.csv\"\n",
        "\n",
        "test_df = pd.read_csv(test_data_path)\n",
        "assert \"statement\" in test_df.columns, \"Test CSV must have a 'statement' column.\"\n",
        "\n",
        "# Encode test statements\n",
        "encoded_test = [tokenizer.encode(text, add_special_tokens=True, truncation=True, max_length=MAX_LEN)\n",
        "                for text in test_df[\"statement\"].values]\n",
        "\n",
        "# Predict\n",
        "predicted_labels = []\n",
        "with torch.no_grad():\n",
        "    for enc in encoded_test:\n",
        "        input_tensor = torch.tensor(enc).unsqueeze(0).to(device)\n",
        "        output = model(input_tensor)\n",
        "        _, pred = torch.max(output, 1)\n",
        "        label = le.inverse_transform(pred.cpu().numpy())[0]\n",
        "        predicted_labels.append(label)\n",
        "\n",
        "# Save results\n",
        "test_df[\"Predicted_Status\"] = predicted_labels\n",
        "\n",
        "if \"status\" in test_df.columns:\n",
        "    test_df.rename(columns={\"status\": \"Actual_Status\"}, inplace=True)\n",
        "    actual = le.transform(test_df[\"Actual_Status\"])\n",
        "    pred = le.transform(test_df[\"Predicted_Status\"])\n",
        "    acc = accuracy_score(actual, pred)\n",
        "    f1 = f1_score(actual, pred, average=\"weighted\")\n",
        "    prec = precision_score(actual, pred, average=\"weighted\")\n",
        "    rec = recall_score(actual, pred, average=\"weighted\")\n",
        "    print(f\"\\n‚úÖ Test Set Results:\\nAccuracy: {acc:.4f} | F1: {f1:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f}\")\n",
        "\n",
        "    cm = confusion_matrix(actual, pred)\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "    plt.title(\"Confusion Matrix (Test Set)\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"True\")\n",
        "    plt.show()\n",
        "\n",
        "# Save CSV\n",
        "test_df.to_csv(output_path, index=False)\n",
        "print(f\"‚úÖ Predictions saved to:\\n{output_path}\")\n"
      ],
      "metadata": {
        "id": "a9wDrcFMtvWH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# STEP 9: Compare Predictions with Actual Status\n",
        "# ==========================================================\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "if \"Actual_Status\" in test_df.columns and \"Predicted_Status\" in test_df.columns:\n",
        "    # Encode actual and predicted labels\n",
        "    y_true = le.transform(test_df[\"Actual_Status\"])\n",
        "    y_pred = le.transform(test_df[\"Predicted_Status\"])\n",
        "\n",
        "    # Compute loss on test set\n",
        "    test_loss = 0\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for enc, label in zip(encoded_test, y_true):\n",
        "            input_tensor = torch.tensor(enc).unsqueeze(0).to(device)\n",
        "            label_tensor = torch.tensor([label]).to(device)\n",
        "            output = model(input_tensor)\n",
        "            loss = criterion(output, label_tensor)\n",
        "            test_loss += loss.item()\n",
        "    avg_test_loss = test_loss / len(encoded_test)\n",
        "\n",
        "    # Metrics\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
        "    prec = precision_score(y_true, y_pred, average='weighted')\n",
        "    rec = recall_score(y_true, y_pred, average='weighted')\n",
        "\n",
        "    print(\"\\n==================== Test Evaluation ====================\")\n",
        "    print(f\"‚úÖ Test Accuracy: {acc:.4f}\")\n",
        "    print(f\"‚úÖ Test F1-Score: {f1:.4f}\")\n",
        "    print(f\"‚úÖ Test Precision: {prec:.4f}\")\n",
        "    print(f\"‚úÖ Test Recall: {rec:.4f}\")\n",
        "    print(f\"‚úÖ Average Test Loss: {avg_test_loss:.4f}\")\n",
        "\n",
        "    print(\"\\nDetailed Classification Report:\")\n",
        "    print(classification_report(y_true, y_pred, target_names=le.classes_))\n",
        "\n",
        "    # Confusion Matrix\n",
        "    cm = confusion_matrix(y_true, y_pred)\n",
        "    plt.figure(figsize=(8,6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Greens',\n",
        "                xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "    plt.title(\"üß† Confusion Matrix ‚Äî Test Set\")\n",
        "    plt.xlabel(\"Predicted\")\n",
        "    plt.ylabel(\"Actual\")\n",
        "    plt.show()\n",
        "\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Test data must include both 'Actual_Status' and 'Predicted_Status' columns to compute metrics.\")\n"
      ],
      "metadata": {
        "id": "ECoPHG9PuA2U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# STEP 10: Single Sentence Prediction Function\n",
        "# ==========================================================\n",
        "\n",
        "def predict_single_sentence(sentence, model, tokenizer, label_encoder, max_len=64):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        # Tokenize and encode the input\n",
        "        encoded = tokenizer.encode(sentence, add_special_tokens=True, truncation=True, max_length=max_len)\n",
        "        input_tensor = torch.tensor(encoded).unsqueeze(0).to(device)\n",
        "\n",
        "        # Forward pass\n",
        "        output = model(input_tensor)\n",
        "        _, predicted_class = torch.max(output, dim=1)\n",
        "\n",
        "        # Decode predicted label\n",
        "        predicted_label = label_encoder.inverse_transform(predicted_class.cpu().numpy())[0]\n",
        "    return predicted_label\n",
        "\n",
        "\n",
        "# ==========================================================\n",
        "# Example: Use the function interactively\n",
        "# ==========================================================\n",
        "example_sentence = \"I feel so hopeless and tired of everything lately.\"\n",
        "predicted_status = predict_single_sentence(example_sentence, model, tokenizer, le)\n",
        "\n",
        "print(f\"\\nüó£Ô∏è Input Sentence: {example_sentence}\")\n",
        "print(f\"ü§ñ Predicted Mental State: {predicted_status}\")\n"
      ],
      "metadata": {
        "id": "x-LuJVsZuN9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# STEP 11 (UPDATED): Accuracy Comparison between Training and Testing\n",
        "# ==========================================================\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "model.eval()\n",
        "train_preds, train_labels_all = [], []\n",
        "\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        train_preds.extend(preds.cpu().numpy())\n",
        "        train_labels_all.extend(labels.cpu().numpy())\n",
        "\n",
        "train_accuracy = accuracy_score(train_labels_all, train_preds)\n",
        "\n",
        "if \"Actual_Status\" in test_df.columns and \"Predicted_Status\" in test_df.columns:\n",
        "    test_accuracy = accuracy_score(\n",
        "        le.transform(test_df[\"Actual_Status\"]),\n",
        "        le.transform(test_df[\"Predicted_Status\"])\n",
        "    )\n",
        "\n",
        "    # Plot Bar Chart\n",
        "    accuracies = [train_accuracy, test_accuracy]\n",
        "    labels = ['Training Accuracy', 'Testing Accuracy']\n",
        "\n",
        "    plt.figure(figsize=(7, 5))\n",
        "    bars = plt.bar(labels, accuracies, color=['skyblue', 'lightgreen'], edgecolor='black')\n",
        "    plt.ylim(0, 1.0)\n",
        "    plt.ylabel(\"Accuracy\")\n",
        "    plt.title(\"Training vs Testing Accuracy Comparison\")\n",
        "\n",
        "    for bar in bars:\n",
        "        height = bar.get_height()\n",
        "        plt.text(bar.get_x() + bar.get_width()/2, height + 0.01, f\"{height:.4f}\",\n",
        "                 ha='center', fontsize=10, fontweight='bold')\n",
        "\n",
        "    acc_chart_path = os.path.join(save_dir, \"Accuracy_Comparison.png\")\n",
        "    plt.savefig(acc_chart_path, bbox_inches='tight', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    print(f\"‚úÖ Saved Accuracy Comparison Chart: {acc_chart_path}\")\n",
        "else:\n",
        "    print(\"‚ö†Ô∏è Test accuracy could not be computed (missing columns).\")\n"
      ],
      "metadata": {
        "id": "lANNiMASuRaq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ==========================================================\n",
        "# STEP 12 (UPDATED): Confusion Matrix & Heatmap for Train and Test Data\n",
        "# ==========================================================\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "# ---- Training ----\n",
        "train_preds, train_labels_all = [], []\n",
        "model.eval()\n",
        "with torch.no_grad():\n",
        "    for inputs, labels in train_loader:\n",
        "        inputs, labels = inputs.to(device), labels.to(device)\n",
        "        outputs = model(inputs)\n",
        "        _, preds = torch.max(outputs, 1)\n",
        "        train_preds.extend(preds.cpu().numpy())\n",
        "        train_labels_all.extend(labels.cpu().numpy())\n",
        "\n",
        "train_cm = confusion_matrix(train_labels_all, train_preds)\n",
        "train_acc = accuracy_score(train_labels_all, train_preds)\n",
        "\n",
        "# ---- Testing ----\n",
        "y_true_test = le.transform(test_df[\"Actual_Status\"])\n",
        "y_pred_test = le.transform(test_df[\"Predicted_Status\"])\n",
        "test_cm = confusion_matrix(y_true_test, y_pred_test)\n",
        "test_acc = accuracy_score(y_true_test, y_pred_test)\n",
        "\n",
        "# ---- Training Confusion Matrix ----\n",
        "plt.figure(figsize=(7, 6))\n",
        "sns.heatmap(train_cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.title(f\"Training Confusion Matrix (Accuracy: {train_acc:.4f})\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "train_cm_path = os.path.join(save_dir, \"Training_Confusion_Matrix.png\")\n",
        "plt.savefig(train_cm_path, bbox_inches='tight', dpi=300)\n",
        "plt.close()\n",
        "\n",
        "# ---- Testing Confusion Matrix ----\n",
        "plt.figure(figsize=(7, 6))\n",
        "sns.heatmap(test_cm, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
        "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.title(f\"Testing Confusion Matrix (Accuracy: {test_acc:.4f})\")\n",
        "plt.xlabel(\"Predicted Labels\")\n",
        "plt.ylabel(\"True Labels\")\n",
        "test_cm_path = os.path.join(save_dir, \"Testing_Confusion_Matrix.png\")\n",
        "plt.savefig(test_cm_path, bbox_inches='tight', dpi=300)\n",
        "plt.close()\n",
        "\n",
        "# ---- Combined Side-by-Side ----\n",
        "plt.figure(figsize=(14, 6))\n",
        "plt.subplot(1, 2, 1)\n",
        "sns.heatmap(train_cm, annot=True, fmt=\"d\", cmap=\"Blues\",\n",
        "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.title(f\"Training Confusion Matrix (Accuracy: {train_acc:.4f})\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "sns.heatmap(test_cm, annot=True, fmt=\"d\", cmap=\"Greens\",\n",
        "            xticklabels=le.classes_, yticklabels=le.classes_)\n",
        "plt.title(f\"Testing Confusion Matrix (Accuracy: {test_acc:.4f})\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"True\")\n",
        "\n",
        "plt.tight_layout()\n",
        "combined_cm_path = os.path.join(save_dir, \"Combined_Confusion_Matrix.png\")\n",
        "plt.savefig(combined_cm_path, bbox_inches='tight', dpi=300)\n",
        "plt.close()\n",
        "\n",
        "print(f\"\"\"\n",
        "‚úÖ All confusion matrices saved:\n",
        "   - Training: {train_cm_path}\n",
        "   - Testing:  {test_cm_path}\n",
        "   - Combined: {combined_cm_path}\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "id": "fmxZ362OuTxw"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}