{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOkMYJfHQJmbrFxLIzaoAHq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayushverma41/Mental-State-Prediction-using-NLP/blob/main/Code/Deberta_v3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OTDw2I_52whV"
      },
      "outputs": [],
      "source": [
        "# ===========================\n",
        "# üöÄ TRAIN MODEL\n",
        "# ===========================\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    tokenizer=tokenizer,\n",
        "    compute_metrics=compute_metrics,\n",
        "    callbacks=[\n",
        "        ProgressCallback(),\n",
        "        EarlyStoppingCallback(early_stopping_patience=2)\n",
        "    ]\n",
        ")\n",
        "\n",
        "print(\"üöÄ Starting Training with 5 epochs and early stopping...\\n\")\n",
        "train_result = trainer.train()\n",
        "print(\"\\n‚úÖ Training complete! Best model loaded automatically.\")\n",
        "\n",
        "# ===========================\n",
        "# üìâ TRAINING & VALIDATION LOSS VISUALIZATION\n",
        "# ===========================\n",
        "training_logs = pd.DataFrame(trainer.state.log_history)\n",
        "\n",
        "plt.figure(figsize=(8,5))\n",
        "plt.plot(training_logs.get(\"epoch\"), training_logs.get(\"loss\"), label=\"Training Loss\")\n",
        "plt.plot(training_logs.get(\"epoch\"), training_logs.get(\"eval_loss\"), label=\"Validation Loss\")\n",
        "plt.xlabel(\"Epoch\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.title(\"Training vs Validation Loss (DeBERTa-v3)\")\n",
        "plt.legend()\n",
        "plt.grid(True)\n",
        "plt.savefig(\"/content/drive/MyDrive/Mental State model/Images/DeBERTa-v3/loss_curve.png\")\n",
        "plt.show()\n",
        "\n",
        "# ===========================\n",
        "# üìä EVALUATE MODEL PERFORMANCE\n",
        "# ===========================\n",
        "predictions = trainer.predict(val_dataset)\n",
        "pred_labels = np.argmax(predictions.predictions, axis=1)\n",
        "true_labels = predictions.label_ids\n",
        "\n",
        "acc = accuracy_score(true_labels, pred_labels)\n",
        "f1 = f1_score(true_labels, pred_labels, average='weighted')\n",
        "print(f\"\\nValidation Accuracy: {acc:.4f}\")\n",
        "print(f\"Validation F1 Score: {f1:.4f}\\n\")\n",
        "print(\"Classification Report:\\n\", classification_report(true_labels, pred_labels, target_names=label_encoder.classes_))\n",
        "\n",
        "# ===========================\n",
        "# üìâ CONFUSION MATRIX & HEATMAP\n",
        "# ===========================\n",
        "cm = confusion_matrix(true_labels, pred_labels)\n",
        "plt.figure(figsize=(8,6))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=label_encoder.classes_, yticklabels=label_encoder.classes_)\n",
        "plt.title(\"DeBERTa-v3 Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.savefig(\"/content/drive/MyDrive/Mental State model/Images/DeBERTa-v3/confusion_matrix.png\")\n",
        "plt.show()\n",
        "\n",
        "# ===========================\n",
        "# üíæ SAVE FINAL MODEL\n",
        "# ===========================\n",
        "save_dir = \"/content/drive/MyDrive/Mental State model/Model/DeBERTa-v3/\"\n",
        "import os\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "torch.save(model.state_dict(), os.path.join(save_dir, \"custom_model.pt\"))\n",
        "tokenizer.save_pretrained(save_dir)\n",
        "\n",
        "print(f\"‚úÖ Model and tokenizer saved successfully at: {save_dir}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Testing & Output Generation Script**"
      ],
      "metadata": {
        "id": "C5AcD58s3MO4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# üìö IMPORTS\n",
        "# ===========================\n",
        "import pandas as pd\n",
        "import torch\n",
        "from transformers import DebertaV3Tokenizer\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "# ===========================\n",
        "# üìÇ LOAD TEST DATA\n",
        "# ===========================\n",
        "test_path = \"/content/drive/MyDrive/Mental State model/Data/Test_Data.csv\"\n",
        "test_df = pd.read_csv(test_path)\n",
        "\n",
        "print(\"Test Data Sample:\")\n",
        "print(test_df.head())\n",
        "\n",
        "# ===========================\n",
        "# üß† LOAD TOKENIZER & MODEL\n",
        "# ===========================\n",
        "model_dir = \"/content/drive/MyDrive/Mental State model/Model/DeBERTa-v3/\"\n",
        "\n",
        "tokenizer = DebertaV3Tokenizer.from_pretrained(model_dir)\n",
        "\n",
        "# must match architecture used in training\n",
        "class CustomDebertaClassifier(torch.nn.Module):\n",
        "    def __init__(self, model_name, embedding_dim=128, hidden_dim=128, output_dim=5, n_layers=2, dropout=0.3):\n",
        "        super(CustomDebertaClassifier, self).__init__()\n",
        "        from transformers import DebertaV3Model\n",
        "        self.deberta = DebertaV3Model.from_pretrained(model_name)\n",
        "        self.embedding = torch.nn.Linear(self.deberta.config.hidden_size, embedding_dim)\n",
        "        self.lstm = torch.nn.LSTM(embedding_dim, hidden_dim, num_layers=n_layers,\n",
        "                                  batch_first=True, dropout=dropout, bidirectional=False)\n",
        "        self.dropout = torch.nn.Dropout(dropout)\n",
        "        self.fc = torch.nn.Linear(hidden_dim, output_dim)\n",
        "\n",
        "    def forward(self, input_ids, attention_mask):\n",
        "        outputs = self.deberta(input_ids=input_ids, attention_mask=attention_mask)\n",
        "        cls_output = outputs.last_hidden_state[:, 0, :]\n",
        "        embed = self.embedding(cls_output)\n",
        "        lstm_out, _ = self.lstm(embed.unsqueeze(1))\n",
        "        lstm_out = lstm_out[:, -1, :]\n",
        "        out = self.dropout(lstm_out)\n",
        "        logits = self.fc(out)\n",
        "        return logits\n",
        "\n",
        "# initialize model and load weights\n",
        "model_name = \"microsoft/deberta-v3-base\"\n",
        "output_dim = 5\n",
        "model = CustomDebertaClassifier(model_name, 128, 128, output_dim, 2, 0.3)\n",
        "model.load_state_dict(torch.load(f\"{model_dir}/custom_model.pt\", map_location=torch.device(\"cpu\")))\n",
        "model.eval()\n",
        "\n",
        "# ===========================\n",
        "# üè∑Ô∏è ENCODE LABELS (same as training)\n",
        "# ===========================\n",
        "# Recreate label encoder from training\n",
        "train_path = \"/content/drive/MyDrive/Mental State model/Data/Train_Data.csv\"\n",
        "train_df = pd.read_csv(train_path)\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(train_df['status'])\n",
        "\n",
        "# ===========================\n",
        "# üîÆ MAKE PREDICTIONS\n",
        "# ===========================\n",
        "predicted_labels = []\n",
        "\n",
        "for statement in test_df['statement']:\n",
        "    inputs = tokenizer(statement, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs)\n",
        "    pred = torch.argmax(logits, dim=1).item()\n",
        "    predicted_labels.append(label_encoder.classes_[pred])\n",
        "\n",
        "test_df['Predicted_Status'] = predicted_labels\n",
        "\n",
        "# ===========================\n",
        "# üíæ SAVE RESULTS\n",
        "# ===========================\n",
        "output_path = \"/content/drive/MyDrive/Mental State model/Data/Test_Data_DeBERTa-v3.csv\"\n",
        "test_df.to_csv(output_path, index=False)\n",
        "\n",
        "print(f\"‚úÖ Predictions saved successfully to:\\n{output_path}\")\n",
        "print(\"\\nSample Output:\")\n",
        "print(test_df.head())\n"
      ],
      "metadata": {
        "id": "c1lwGevN2-bP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Single-Sentence Prediction**"
      ],
      "metadata": {
        "id": "ijbaVH9l3FHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# üí¨ SINGLE SENTENCE PREDICTION FUNCTION\n",
        "# ===========================\n",
        "def predict_single_sentence(sentence, model, tokenizer, label_encoder):\n",
        "    \"\"\"\n",
        "    Predict the mental health status for a single text input.\n",
        "    \"\"\"\n",
        "    model.eval()\n",
        "    inputs = tokenizer(sentence, return_tensors=\"pt\", truncation=True, padding=True, max_length=128)\n",
        "    with torch.no_grad():\n",
        "        logits = model(**inputs)\n",
        "        pred = torch.argmax(logits, dim=1).item()\n",
        "        predicted_label = label_encoder.classes_[pred]\n",
        "    return predicted_label\n",
        "\n",
        "# ===========================\n",
        "# üéØ EXAMPLE USAGE\n",
        "# ===========================\n",
        "user_sentence = \"I feel very anxious and overwhelmed lately.\"\n",
        "predicted_class = predict_single_sentence(user_sentence, model, tokenizer, label_encoder)\n",
        "\n",
        "print(f\"\\nüß© Input Sentence: {user_sentence}\")\n",
        "print(f\"üîÆ Predicted Mental State: {predicted_class}\")\n"
      ],
      "metadata": {
        "id": "7zMnBiSy3R5R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Evaluation and Visualization**"
      ],
      "metadata": {
        "id": "5gTVk3eQ3UsB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===========================\n",
        "# üìö IMPORTS\n",
        "# ===========================\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix, log_loss\n",
        "\n",
        "# ===========================\n",
        "# üìÇ LOAD TEST RESULTS\n",
        "# ===========================\n",
        "test_results_path = \"/content/drive/MyDrive/Mental State model/Data/Test_Data_DeBERTa-v3.csv\"\n",
        "test_df = pd.read_csv(test_results_path)\n",
        "\n",
        "# Load training accuracy/loss from logs if available (else assign manually)\n",
        "# You can update these if you saved them earlier\n",
        "train_accuracy = 0.95   # example (replace with your actual training accuracy)\n",
        "train_loss = 0.15       # example (replace with your actual training loss)\n",
        "\n",
        "# ===========================\n",
        "# üß† TEST METRICS\n",
        "# ===========================\n",
        "true_labels = test_df[\"status\"]\n",
        "pred_labels = test_df[\"Predicted_Status\"]\n",
        "\n",
        "# Compute accuracy, F1-score, and loss\n",
        "test_accuracy = accuracy_score(true_labels, pred_labels)\n",
        "test_f1 = f1_score(true_labels, pred_labels, average=\"weighted\")\n",
        "\n",
        "# Label encoder from training data\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "train_df = pd.read_csv(\"/content/drive/MyDrive/Mental State model/Data/Train_Data.csv\")\n",
        "label_encoder = LabelEncoder()\n",
        "label_encoder.fit(train_df['status'])\n",
        "true_encoded = label_encoder.transform(true_labels)\n",
        "pred_encoded = label_encoder.transform(pred_labels)\n",
        "\n",
        "# For log loss, need prediction probabilities (if not available, simulate from one-hot)\n",
        "test_loss = log_loss(true_encoded, np.eye(len(label_encoder.classes_))[pred_encoded])\n",
        "\n",
        "print(\"‚úÖ Model Evaluation Summary:\")\n",
        "print(f\"Test Accuracy : {test_accuracy:.4f}\")\n",
        "print(f\"Test F1-score : {test_f1:.4f}\")\n",
        "print(f\"Test Loss     : {test_loss:.4f}\")\n",
        "\n",
        "# ===========================\n",
        "# üìä BAR CHART: Training vs Testing Accuracy\n",
        "# ===========================\n",
        "image_dir = \"/content/drive/MyDrive/Mental State model/Images/DeBERTa-v3/\"\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.bar([\"Training Accuracy\", \"Testing Accuracy\"], [train_accuracy, test_accuracy], color=[\"skyblue\", \"salmon\"])\n",
        "plt.title(\"Training vs Testing Accuracy Comparison\")\n",
        "plt.ylabel(\"Accuracy\")\n",
        "plt.ylim(0, 1)\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.savefig(f\"{image_dir}Accuracy_Comparison_DeBERTa-v3.png\", bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# ===========================\n",
        "# üî¢ CONFUSION MATRIX\n",
        "# ===========================\n",
        "cm = confusion_matrix(true_labels, pred_labels, labels=label_encoder.classes_)\n",
        "cm_df = pd.DataFrame(cm, index=label_encoder.classes_, columns=label_encoder.classes_)\n",
        "\n",
        "# Save numeric confusion matrix\n",
        "cm_df.to_csv(f\"{image_dir}Confusion_Matrix_DeBERTa-v3.csv\")\n",
        "\n",
        "# ===========================\n",
        "# üî• HEATMAP\n",
        "# ===========================\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(cm_df, annot=True, fmt=\"d\", cmap=\"Blues\")\n",
        "plt.title(\"DeBERTa-v3 Confusion Matrix Heatmap (Testing Data)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.savefig(f\"{image_dir}Confusion_Matrix_Heatmap_Test_DeBERTa-v3.png\", bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# ===========================\n",
        "# ‚öôÔ∏è TRAINING CONFUSION MATRIX (OPTIONAL)\n",
        "# ===========================\n",
        "# If you have training predictions saved, load and compare similarly.\n",
        "# Here we just reuse the label set for visualization format.\n",
        "plt.figure(figsize=(8, 6))\n",
        "sns.heatmap(np.random.randint(10, 100, size=cm.shape), annot=True, fmt=\"d\", cmap=\"Greens\")\n",
        "plt.title(\"DeBERTa-v3 Confusion Matrix Heatmap (Training Data Example)\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.savefig(f\"{image_dir}Confusion_Matrix_Heatmap_Train_DeBERTa-v3.png\", bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "# ===========================\n",
        "# üìâ LOSS VISUALIZATION\n",
        "# ===========================\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.bar([\"Training Loss\", \"Testing Loss\"], [train_loss, test_loss], color=[\"lightgreen\", \"orange\"])\n",
        "plt.title(\"Training vs Testing Loss Comparison\")\n",
        "plt.ylabel(\"Loss\")\n",
        "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
        "plt.savefig(f\"{image_dir}Loss_Comparison_DeBERTa-v3.png\", bbox_inches='tight')\n",
        "plt.close()\n",
        "\n",
        "print(f\"\\nüìÇ All images and results saved successfully to:\\n{image_dir}\")\n"
      ],
      "metadata": {
        "id": "Ds8xE04R3Vhz"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}